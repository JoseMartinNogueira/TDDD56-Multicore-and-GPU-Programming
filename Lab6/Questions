1- Question: How is the communication between the host and the graphic card handled?
	By buffers
	input = clCreateBuffer(context,  CL_MEM_READ_ONLY | CL_MEM_USE_HOST_PTR,  sizeof(char) * DATA_SIZE, a, NULL);
	
	
2- Question: What function executes your kernel?
	err = clEnqueueNDRangeKernel(commands, kernel, 1, NULL, &global, &local, 0, NULL, NULL);

3- Question: How does the kernel know what element to work on?
	int i = get_global_id(0);

4- QUESTION: What timing did you get for your GPU reduction? Compare it to the CPU version.
	GPU 0.001357
	CPU 0.000005
5- QUESTION: Try larger data size. On what size does the GPU version get faster, or at least comparable, to the GPU?
	In GPU the time is always pretty much the same while in CPU increases with the entry size

6- QUESTION: How can you optimize this further? You should know at least one way.
	if there is less than X values use the CPU.

7- QUESTION: Should each thread produce one output or two? Why?
	there is not output, each thread swap numbers. 

8- QUESTION: How many items can you handle in one workgroup?
	localworkSize*2 = 512*2

9- QUESTION: What problem must be solved when you use more than one workgroup? How did you solve it?
	the data that each workgroup has to handle. with 2 loops

10- QUESTION: What time do you get? Difference to the CPU? What is the break even size? What can you expect for a parallel CPU version? (Your conclusions here may vary between the labs.)
	CPU 1024 = 0.000485
	GPU 1024 = 0.000893
	CPU 1024*2 = 0.001295
	GPU 1024*2 = 0.001067
	CPU 1024*3 = 0.001999
	GPU 1024*3 = 0.001107
	CPU 1024*4 = 0.003231
	GPU 1024*4 = 0.001217
	
